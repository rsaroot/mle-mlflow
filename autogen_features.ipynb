{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2609d485",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import (\n",
    "    OneHotEncoder, \n",
    "    SplineTransformer, \n",
    "    QuantileTransformer, \n",
    "    RobustScaler,\n",
    "    PolynomialFeatures,\n",
    "    KBinsDiscretizer,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, precision_score, recall_score, f1_score, log_loss, confusion_matrix,\n",
    ")\n",
    "from mlflow.models.signature import ModelSignature\n",
    "from mlflow.types.schema import Schema, ColSpec\n",
    "\n",
    "import psycopg\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from autofeat import AutoFeatClassifier\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7724d6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"DB_DESTINATION_HOST\"] = os.getenv(\"DB_DESTINATION_HOST\")\n",
    "os.environ[\"DB_DESTINATION_PORT\"] = os.getenv(\"DB_DESTINATION_PORT\")\n",
    "os.environ[\"DB_DESTINATION_NAME\"] = os.getenv(\"DB_DESTINATION_NAME\")\n",
    "os.environ[\"DB_DESTINATION_USER\"] = os.getenv(\"DB_DESTINATION_USER\")\n",
    "os.environ[\"DB_DESTINATION_PASSWORD\"] = os.getenv(\"DB_DESTINATION_PASSWORD\")\n",
    "\n",
    "os.environ[\"MLFLOW_S3_ENDPOINT_URL\"] = \"https://storage.yandexcloud.net\" #endpoint бакета от YandexCloud\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"] = os.getenv(\"AWS_ACCESS_KEY_ID\") # получаем id ключа бакета, к которому подключён MLFlow, из .env\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = os.getenv(\"AWS_SECRET_ACCESS_KEY\") # получаем ключ бакета, к которому подключён MLFlow, из .env\n",
    "\n",
    "# определяем глобальные переменные\n",
    "# поднимаем MLflow локально\n",
    "TRACKING_SERVER_HOST = \"127.0.0.1\"\n",
    "TRACKING_SERVER_PORT = 5000\n",
    "\n",
    "\n",
    "registry_uri = f\"http://{TRACKING_SERVER_HOST}:{TRACKING_SERVER_PORT}\"\n",
    "tracking_uri = f\"http://{TRACKING_SERVER_HOST}:{TRACKING_SERVER_PORT}\"\n",
    "\n",
    "mlflow.set_tracking_uri(tracking_uri)\n",
    "\n",
    "# название тестового эксперимента и запуска (run) внутри него\n",
    "EXPERIMENT_NAME = \"real_churn_sergey_sh_final\"\n",
    "RUN_NAME = \"feature_autogen\"\n",
    "REGISTRY_MODEL_NAME = \"churn_model_sergey_sh\"\n",
    "FS_ASSETS = \"fs_assets\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb5f63b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>begin_date</th>\n",
       "      <th>end_date</th>\n",
       "      <th>type</th>\n",
       "      <th>paperless_billing</th>\n",
       "      <th>payment_method</th>\n",
       "      <th>monthly_charges</th>\n",
       "      <th>total_charges</th>\n",
       "      <th>internet_service</th>\n",
       "      <th>...</th>\n",
       "      <th>device_protection</th>\n",
       "      <th>tech_support</th>\n",
       "      <th>streaming_tv</th>\n",
       "      <th>streaming_movies</th>\n",
       "      <th>gender</th>\n",
       "      <th>senior_citizen</th>\n",
       "      <th>partner</th>\n",
       "      <th>dependents</th>\n",
       "      <th>multiple_lines</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>7795-CFOCW</td>\n",
       "      <td>2016-05-01</td>\n",
       "      <td>NaT</td>\n",
       "      <td>One year</td>\n",
       "      <td>No</td>\n",
       "      <td>Bank transfer (automatic)</td>\n",
       "      <td>42.30</td>\n",
       "      <td>1840.75</td>\n",
       "      <td>DSL</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>9237-HQITU</td>\n",
       "      <td>2019-09-01</td>\n",
       "      <td>2019-11-01</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>70.70</td>\n",
       "      <td>151.65</td>\n",
       "      <td>Fiber optic</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>9305-CDSKC</td>\n",
       "      <td>2019-03-01</td>\n",
       "      <td>2019-11-01</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>99.65</td>\n",
       "      <td>820.50</td>\n",
       "      <td>Fiber optic</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1452-KIOVK</td>\n",
       "      <td>2018-04-01</td>\n",
       "      <td>NaT</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Credit card (automatic)</td>\n",
       "      <td>89.10</td>\n",
       "      <td>1949.40</td>\n",
       "      <td>Fiber optic</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>6713-OKOMC</td>\n",
       "      <td>2019-04-01</td>\n",
       "      <td>NaT</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>No</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>29.75</td>\n",
       "      <td>301.90</td>\n",
       "      <td>DSL</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id customer_id begin_date   end_date            type paperless_billing  \\\n",
       "0   1  7795-CFOCW 2016-05-01        NaT        One year                No   \n",
       "1   2  9237-HQITU 2019-09-01 2019-11-01  Month-to-month               Yes   \n",
       "2   3  9305-CDSKC 2019-03-01 2019-11-01  Month-to-month               Yes   \n",
       "3   4  1452-KIOVK 2018-04-01        NaT  Month-to-month               Yes   \n",
       "4   5  6713-OKOMC 2019-04-01        NaT  Month-to-month                No   \n",
       "\n",
       "              payment_method  monthly_charges  total_charges internet_service  \\\n",
       "0  Bank transfer (automatic)            42.30        1840.75              DSL   \n",
       "1           Electronic check            70.70         151.65      Fiber optic   \n",
       "2           Electronic check            99.65         820.50      Fiber optic   \n",
       "3    Credit card (automatic)            89.10        1949.40      Fiber optic   \n",
       "4               Mailed check            29.75         301.90              DSL   \n",
       "\n",
       "   ... device_protection tech_support streaming_tv streaming_movies  gender  \\\n",
       "0  ...               Yes          Yes           No               No    Male   \n",
       "1  ...                No           No           No               No  Female   \n",
       "2  ...               Yes           No          Yes              Yes  Female   \n",
       "3  ...                No           No          Yes               No    Male   \n",
       "4  ...                No           No           No               No  Female   \n",
       "\n",
       "  senior_citizen partner  dependents multiple_lines target  \n",
       "0              0      No          No             No      0  \n",
       "1              0      No          No             No      1  \n",
       "2              0      No          No            Yes      1  \n",
       "3              0      No         Yes            Yes      0  \n",
       "4              0      No          No             No      0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "connection = {\"sslmode\": \"require\", \"target_session_attrs\": \"read-write\"}\n",
    "postgres_credentials = {\n",
    "    \"host\": os.environ[\"DB_DESTINATION_HOST\"], \n",
    "    \"port\": os.environ[\"DB_DESTINATION_PORT\"],\n",
    "    \"dbname\": os.environ[\"DB_DESTINATION_NAME\"],\n",
    "    \"user\": os.environ[\"DB_DESTINATION_USER\"],\n",
    "    \"password\": os.environ[\"DB_DESTINATION_PASSWORD\"],\n",
    "}\n",
    "assert all([var_value != \"\" for var_value in list(postgres_credentials.values())])\n",
    "\n",
    "connection.update(postgres_credentials)\n",
    "\n",
    "# определим название таблицы, в которой хранятся наши данные.\n",
    "TABLE_NAME = \"clean_users_churn\"\n",
    "\n",
    "# эта конструкция создаёт контекстное управление для соединения с базой данных \n",
    "# оператор with гарантирует, что соединение будет корректно закрыто после выполнения всех операций \n",
    "# закрыто оно будет даже в случае ошибки, чтобы не допустить \"утечку памяти\"\n",
    "with psycopg.connect(**connection) as conn:\n",
    "\n",
    "# создаёт объект курсора для выполнения запросов к базе данных\n",
    "# с помощью метода execute() выполняется SQL-запрос для выборки данных из таблицы TABLE_NAME\n",
    "    with conn.cursor() as cur:\n",
    "        cur.execute(f\"SELECT * FROM {TABLE_NAME}\")\n",
    "                \n",
    "                # извлекаем все строки, полученные в результате выполнения запроса\n",
    "        data = cur.fetchall()\n",
    "\n",
    "                # получает список имён столбцов из объекта курсора\n",
    "        columns = [col[0] for col in cur.description]\n",
    "\n",
    "# создаёт объект DataFrame из полученных данных и имён столбцов. \n",
    "# это позволяет удобно работать с данными в Python, используя библиотеку Pandas.\n",
    "df = pd.DataFrame(data, columns=columns)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7411fae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mle-user/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/mle-user/.venv/lib/python3.10/site-packages/autofeat/featsel.py:270: FutureWarning: Series.ravel is deprecated. The underlying array is already 1D, so ravel is not necessary.  Use `to_numpy()` for conversion to a numpy array instead.\n",
      "  if np.max(np.abs(correlations[c].ravel()[:i])) < 0.9:\n",
      "/home/mle-user/.venv/lib/python3.10/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "split_column = \"begin_date\"\n",
    "test_size = 0.2\n",
    "\n",
    "cat_features = [\n",
    "    'paperless_billing',\n",
    "    'payment_method',\n",
    "    'internet_service',\n",
    "    'online_security',\n",
    "    'online_backup',\n",
    "    'device_protection',\n",
    "    'tech_support',\n",
    "    'streaming_tv',\n",
    "    'streaming_movies',\n",
    "    'gender',\n",
    "    'senior_citizen',\n",
    "    'partner',\n",
    "    'dependents',\n",
    "    'multiple_lines',\n",
    "]\n",
    "num_features = [\"monthly_charges\", \"total_charges\"]\n",
    "target = ['target']\n",
    "\n",
    "features = cat_features + num_features\n",
    "\n",
    "df = df.sort_values(by=[split_column])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df[features],\n",
    "    df[target],\n",
    "    test_size=test_size,\n",
    "    shuffle=False,\n",
    ") \n",
    "\n",
    "transformations = ('1/', 'log', 'abs', 'sqrt')\n",
    "\n",
    "afc = AutoFeatClassifier(categorical_cols=cat_features, transformations=transformations, feateng_steps=1, n_jobs=-1)\n",
    "\n",
    "X_train_features = afc.fit_transform(X_train,  y_train)\n",
    "X_test_features = afc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dbb55e8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-25 15:13:05,759 INFO: Found credentials in environment variables.\n"
     ]
    }
   ],
   "source": [
    "artifact_path = \"afc\"\n",
    "experiment_id = mlflow.get_experiment_by_name(EXPERIMENT_NAME).experiment_id\n",
    "\n",
    "with mlflow.start_run(run_name=RUN_NAME, experiment_id=experiment_id) as run:\n",
    "    run_id = run.info.run_id\n",
    "    \n",
    "    afc_info = mlflow.sklearn.log_model(afc, artifact_path=artifact_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3348074d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mle-user/.venv/lib/python3.10/site-packages/sklearn/base.py:1365: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/home/mle-user/.venv/lib/python3.10/site-packages/mlflow/models/signature.py:212: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  inputs = _infer_schema(model_input) if model_input is not None else None\n",
      "/home/mle-user/.venv/lib/python3.10/site-packages/_distutils_hack/__init__.py:15: UserWarning: Distutils was imported before Setuptools, but importing Setuptools also replaces the `distutils` module in `sys.modules`. This may lead to undesirable behaviors or errors. To avoid these issues, avoid using distutils directly, ensure that setuptools is installed in the traditional way (e.g. not an editable install), and/or make sure that setuptools is always imported before distutils.\n",
      "  warnings.warn(\n",
      "/home/mle-user/.venv/lib/python3.10/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml\n",
      "  warnings.warn(\n",
      "Registered model 'churn_model_sergey_sh' already exists. Creating a new version of this model...\n",
      "2025/09/25 15:35:08 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation. Model name: churn_model_sergey_sh, version 5\n",
      "Created version '5' of model 'churn_model_sergey_sh'.\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier()\n",
    "model.fit(X_train_features, y_train)\n",
    "\n",
    "# Предсказания\n",
    "prediction = model.predict(X_test_features)\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, f1_score, precision_score, recall_score, confusion_matrix, log_loss\n",
    "# импортируйте необходимые вам модули\n",
    "\n",
    "# заведите словарь со всеми метриками\n",
    "metrics = {}\n",
    "\n",
    "# посчитайте метрики из модуля sklearn.metrics\n",
    "# err_1 — ошибка первого рода\n",
    "# err_2 — ошибка второго рода\n",
    "_, err1, err2, _ = confusion_matrix(y_test, prediction,normalize='all').ravel()\n",
    "#auc = roc_auc_score(y_test, probas)\n",
    "precision = precision_score(y_test, prediction)\n",
    "recall = recall_score(y_test, prediction)\n",
    "f1 = f1_score(y_test, prediction)\n",
    "logloss = log_loss(y_test, prediction)\n",
    "\n",
    "# запишите значения метрик в словарь\n",
    "metrics[\"err1\"] = err1\n",
    "metrics[\"err2\"] = err2\n",
    "#metrics[\"auc\"] = auc\n",
    "metrics[\"precision\"] = precision\n",
    "metrics[\"recall\"] = recall\n",
    "metrics[\"f1\"] = f1\n",
    "metrics[\"logloss\"] = logloss\n",
    "\n",
    "pip_requirements = \"requirements.txt\"\n",
    "signature = mlflow.models.infer_signature(X_test, prediction)\n",
    "input_example = X_test[:10]\n",
    "metadata =  {'model_type': 'model_with_autogen_features'}\n",
    "\n",
    "experiment = mlflow.get_experiment_by_name(EXPERIMENT_NAME)\n",
    "if experiment is None:\n",
    "    experiment_id = mlflow.create_experiment(EXPERIMENT_NAME)\n",
    "else:\n",
    "    experiment_id = experiment.experiment_id\n",
    "\n",
    "# --- Формирование сигнатуры для логирования --\n",
    "input_schema = Schema([ColSpec(\"double\", name) for name in X_train.columns])\n",
    "output_schema = Schema([ColSpec(\"double\")])\n",
    "signature = ModelSignature(inputs=input_schema, outputs=output_schema)\n",
    "\n",
    "with mlflow.start_run(run_name=RUN_NAME, experiment_id=experiment_id) as run:\n",
    "    mlflow.log_metrics(metrics)\n",
    "\n",
    "    # Пример логгирования артефактов\n",
    "    with open('columns.txt', 'w') as f:\n",
    "        f.writelines([col + '\\n' for col in df.columns])\n",
    "    df.to_csv(\"users_churn.csv\", index=False)\n",
    "    mlflow.log_artifact(\"columns.txt\", \"dataframe\")\n",
    "    mlflow.log_artifact(\"users_churn.csv\", \"dataframe\")\n",
    "\n",
    "    mlflow.set_tags({\n",
    "        \"project\": \"logiruem_model\",\n",
    "        \"team\": \"data_science\",\n",
    "        \"version\": \"4.0\"\n",
    "    })\n",
    "    # логируем метрики\n",
    "    mlflow.log_metrics(metrics)\n",
    "\n",
    "    # Логируем полный пайплайн\n",
    "    mlflow.sklearn.log_model(\n",
    "        sk_model=model,\n",
    "        artifact_path=\"model_pipeline\",\n",
    "        signature=signature,\n",
    "        input_example=X_train.head(2),\n",
    "        registered_model_name=REGISTRY_MODEL_NAME\n",
    "    )\n",
    "\n",
    "    afc_info = mlflow.sklearn.log_model(afc, artifact_path='afc') \n",
    "\n",
    "\n",
    "# Очистка временных файлов\n",
    "for filename in ['columns.txt', 'users_churn.csv']:\n",
    "    if os.path.exists(filename):\n",
    "        os.remove(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e829af42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mle-user/.venv/lib/python3.10/site-packages/sklearn/base.py:1365: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/home/mle-user/.venv/lib/python3.10/site-packages/_distutils_hack/__init__.py:15: UserWarning: Distutils was imported before Setuptools, but importing Setuptools also replaces the `distutils` module in `sys.modules`. This may lead to undesirable behaviors or errors. To avoid these issues, avoid using distutils directly, ensure that setuptools is installed in the traditional way (e.g. not an editable install), and/or make sure that setuptools is always imported before distutils.\n",
      "  warnings.warn(\n",
      "/home/mle-user/.venv/lib/python3.10/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml\n",
      "  warnings.warn(\n",
      "Successfully registered model 'boston_rf_model'.\n",
      "2025/09/25 15:41:48 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation. Model name: boston_rf_model, version 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLflow run completed successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created version '1' of model 'boston_rf_model'.\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "from mlflow.models import ModelSignature\n",
    "from mlflow.types import Schema, ColSpec\n",
    "import os\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train_features, y_train)\n",
    "\n",
    "# Предсказания\n",
    "prediction = model.predict(X_test_features)\n",
    "probas = model.predict_proba(X_test_features)[:, 1]  # для AUC\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, f1_score, precision_score, recall_score, confusion_matrix, log_loss\n",
    "\n",
    "# Расчет метрик\n",
    "metrics = {}\n",
    "\n",
    "# Матрица ошибок\n",
    "cm = confusion_matrix(y_test, prediction)\n",
    "total = len(y_test)\n",
    "err1 = cm[0, 1] / total if total > 0 else 0  # False Positive Rate\n",
    "err2 = cm[1, 0] / total if total > 0 else 0  # False Negative Rate\n",
    "\n",
    "precision = precision_score(y_test, prediction)\n",
    "recall = recall_score(y_test, prediction)\n",
    "f1 = f1_score(y_test, prediction)\n",
    "auc = roc_auc_score(y_test, probas)\n",
    "logloss = log_loss(y_test, probas)\n",
    "\n",
    "# Запись метрик\n",
    "metrics[\"err1\"] = err1\n",
    "metrics[\"err2\"] = err2\n",
    "metrics[\"auc\"] = auc\n",
    "metrics[\"precision\"] = precision\n",
    "metrics[\"recall\"] = recall\n",
    "metrics[\"f1\"] = f1\n",
    "metrics[\"logloss\"] = logloss\n",
    "\n",
    "# Настройки MLflow\n",
    "EXPERIMENT_NAME = \"boston_housing_experiment\"\n",
    "RUN_NAME = \"random_forest_with_features\"\n",
    "REGISTRY_MODEL_NAME = \"boston_rf_model\"\n",
    "\n",
    "# Получение или создание эксперимента\n",
    "experiment = mlflow.get_experiment_by_name(EXPERIMENT_NAME)\n",
    "if experiment is None:\n",
    "    experiment_id = mlflow.create_experiment(EXPERIMENT_NAME)\n",
    "else:\n",
    "    experiment_id = experiment.experiment_id\n",
    "\n",
    "# Создание реальных артефактов для логирования\n",
    "# 1. Сохранение важности признаков\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X_train_features.columns,\n",
    "    'importance': model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "feature_importance.to_csv('feature_importance.csv', index=False)\n",
    "\n",
    "# 2. Сохранение описания модели\n",
    "with open('model_info.txt', 'w') as f:\n",
    "    f.write(f\"RandomForestClassifier\\n\")\n",
    "    f.write(f\"Number of features: {X_train_features.shape[1]}\\n\")\n",
    "    f.write(f\"Number of estimators: {model.n_estimators}\\n\")\n",
    "\n",
    "with mlflow.start_run(run_name=RUN_NAME, experiment_id=experiment_id) as run:\n",
    "    # Логируем параметры модели\n",
    "    mlflow.log_params({\n",
    "        \"n_estimators\": model.n_estimators,\n",
    "        \"max_depth\": model.max_depth,\n",
    "        \"random_state\": model.random_state if hasattr(model, 'random_state') else None\n",
    "    })\n",
    "    \n",
    "    # Логируем метрики\n",
    "    mlflow.log_metrics(metrics)\n",
    "\n",
    "    # Логируем артефакты\n",
    "    mlflow.log_artifact(\"feature_importance.csv\", \"model_info\")\n",
    "    mlflow.log_artifact(\"model_info.txt\", \"model_info\")\n",
    "\n",
    "    mlflow.set_tags({\n",
    "        \"project\": \"boston_housing\",\n",
    "        \"team\": \"data_science\",\n",
    "        \"model_type\": \"random_forest\",\n",
    "        \"version\": \"1.0\"\n",
    "    })\n",
    "\n",
    "    # Создаем сигнатуру для модели\n",
    "    input_schema = Schema([ColSpec(\"double\", name) for name in X_train_features.columns])\n",
    "    output_schema = Schema([ColSpec(\"long\")])  # для классификации\n",
    "    signature = ModelSignature(inputs=input_schema, outputs=output_schema)\n",
    "\n",
    "    # Логируем модель\n",
    "    mlflow.sklearn.log_model(\n",
    "        sk_model=model,\n",
    "        artifact_path=\"model\",\n",
    "        signature=signature,\n",
    "        input_example=X_train_features.head(2),\n",
    "        registered_model_name=REGISTRY_MODEL_NAME\n",
    "    )\n",
    "\n",
    "# Очистка временных файлов\n",
    "for filename in ['feature_importance.csv', 'model_info.txt']:\n",
    "    if os.path.exists(filename):\n",
    "        os.remove(filename)\n",
    "\n",
    "print(\"MLflow run completed successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
