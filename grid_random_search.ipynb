{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f2493d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mle-user/.venv/lib/python3.10/site-packages/mlflow/utils/requirements_utils.py:20: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources  # noqa: TID251\n",
      "/home/mle-user/.venv/lib/python3.10/site-packages/pydantic/_internal/_config.py:373: UserWarning: Valid config keys have changed in V2:\n",
      "* 'schema_extra' has been renamed to 'json_schema_extra'\n",
      "  warnings.warn(message, UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import psycopg\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "from catboost import CatBoostClassifier\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "from mlxtend.plotting import plot_sequential_feature_selection as plot_sfs\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "psycopg\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import roc_auc_score, f1_score, precision_score, recall_score, confusion_matrix, log_loss\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3ecb84b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер выборки для обучения: (5615, 3)\n",
      "Размер выборки для теста: (1404, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mle-user/.venv/lib/python3.10/site-packages/sklearn/model_selection/_search.py:317: UserWarning: The total space of parameters 10 is smaller than n_iter=20. Running 10 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"DB_DESTINATION_HOST\"] = os.getenv(\"DB_DESTINATION_HOST\")\n",
    "os.environ[\"DB_DESTINATION_PORT\"] = os.getenv(\"DB_DESTINATION_PORT\")\n",
    "os.environ[\"DB_DESTINATION_NAME\"] = os.getenv(\"DB_DESTINATION_NAME\")\n",
    "os.environ[\"DB_DESTINATION_USER\"] = os.getenv(\"DB_DESTINATION_USER\")\n",
    "os.environ[\"DB_DESTINATION_PASSWORD\"] = os.getenv(\"DB_DESTINATION_PASSWORD\")\n",
    "\n",
    "os.environ[\"MLFLOW_S3_ENDPOINT_URL\"] = \"https://storage.yandexcloud.net\" #endpoint бакета от YandexCloud\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"] = os.getenv(\"AWS_ACCESS_KEY_ID\") # получаем id ключа бакета, к которому подключён MLFlow, из .env\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = os.getenv(\"AWS_SECRET_ACCESS_KEY\") # получаем ключ бакета, к которому подключён MLFlow, из .env\n",
    "\n",
    "# определим название таблицы, в которой хранятся наши данные.\n",
    "TABLE_NAME = \"clean_users_churn\"\n",
    "\n",
    "# поднимаем MLflow локально\n",
    "TRACKING_SERVER_HOST = \"127.0.0.1\"\n",
    "TRACKING_SERVER_PORT = 5000\n",
    "\n",
    "# название тестового эксперимента и запуска (run) внутри него\n",
    "EXPERIMENT_NAME = \"search_sergey_s\"\n",
    "#RUN_NAME = 'model_grid_search' # ваш код здесь\n",
    "RUN_NAME = 'model_random_search' # ваш код здесь\n",
    "REGISTRY_MODEL_NAME = \"search_model_sergey_s\"\n",
    "\n",
    "connection = {\"sslmode\": \"require\", \"target_session_attrs\": \"read-write\"}\n",
    "postgres_credentials = {\n",
    "    \"host\": os.environ[\"DB_DESTINATION_HOST\"], \n",
    "    \"port\": os.environ[\"DB_DESTINATION_PORT\"],\n",
    "    \"dbname\": os.environ[\"DB_DESTINATION_NAME\"],\n",
    "    \"user\": os.environ[\"DB_DESTINATION_USER\"],\n",
    "    \"password\": os.environ[\"DB_DESTINATION_PASSWORD\"],\n",
    "}\n",
    "assert all([var_value != \"\" for var_value in list(postgres_credentials.values())])\n",
    "\n",
    "connection.update(postgres_credentials)\n",
    "# эта конструкция создаёт контекстное управление для соединения с базой данных \n",
    "# оператор with гарантирует, что соединение будет корректно закрыто после выполнения всех операций \n",
    "# закрыто оно будет даже в случае ошибки, чтобы не допустить \"утечку памяти\"\n",
    "with psycopg.connect(**connection) as conn:\n",
    "\n",
    "# создаёт объект курсора для выполнения запросов к базе данных\n",
    "# с помощью метода execute() выполняется SQL-запрос для выборки данных из таблицы TABLE_NAME\n",
    "    with conn.cursor() as cur:\n",
    "        cur.execute(f\"SELECT * FROM {TABLE_NAME}\")\n",
    "                \n",
    "                # извлекаем все строки, полученные в результате выполнения запроса\n",
    "        data = cur.fetchall()\n",
    "\n",
    "                # получает список имён столбцов из объекта курсора\n",
    "        columns = [col[0] for col in cur.description]\n",
    "\n",
    "# создаёт объект DataFrame из полученных данных и имён столбцов. \n",
    "# это позволяет удобно работать с данными в Python, используя библиотеку Pandas.\n",
    "df = pd.DataFrame(data, columns=columns)\n",
    "\n",
    "features = [\"monthly_charges\", \"total_charges\", \"senior_citizen\"]\n",
    "target = \"target\"\n",
    "split_column = 'begin_date'# ваш код здесь\n",
    "stratify_column = 'begin_date'# ваш код здесь\n",
    "test_size = 0.2# ваш код здесь\n",
    "\n",
    "df = df.sort_values(by=[split_column])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df[features],\n",
    "    df[target],\n",
    "    test_size=test_size,\n",
    "    shuffle=False,\n",
    ") \n",
    "print(f\"Размер выборки для обучения: {X_train.shape}\")\n",
    "print(f\"Размер выборки для теста: {X_test.shape}\")\n",
    "\n",
    "loss_function = \"Logloss\"\n",
    "task_type = 'CPU'\n",
    "random_seed = 0\n",
    "iterations = 300\n",
    "verbose = False\n",
    "\n",
    "param_distributions = {\n",
    "    'iterations' : [5,10,15,20,25,30,35,40,45,50],\n",
    "}\n",
    "\n",
    "model = CatBoostClassifier(loss_function=loss_function, task_type=task_type, iterations=iterations, verbose=verbose,random_seed=random_seed)# ваш код здесь\n",
    "\n",
    "#cv = GridSearchCV(estimator=model, param_grid=param_distributions, cv=2,n_jobs=-1)# ваш код здесь\n",
    "cv = RandomizedSearchCV(estimator=model, param_distributions=param_distributions, cv=2,n_jobs=-1, n_iter=20)# ваш код здесь\n",
    "\n",
    "clf = cv.fit(X_train, y_train) # ваш код здесь\n",
    "\n",
    "\n",
    "mlflow.set_tracking_uri(f\"http://{TRACKING_SERVER_HOST}:{TRACKING_SERVER_PORT}\")\n",
    "mlflow.set_registry_uri(f\"http://{TRACKING_SERVER_HOST}:{TRACKING_SERVER_PORT}\")\n",
    "\n",
    "cv_results =  pd.DataFrame(clf.cv_results_) # ваш код здесь\n",
    "\n",
    "best_params = clf.best_params_# ваш код здесь\n",
    "\n",
    "model_best = CatBoostClassifier(**best_params, loss_function=loss_function, task_type=task_type, verbose=verbose,random_seed=random_seed)# ваш код здесь\n",
    "\n",
    "model_best.fit(X_train, y_train)\n",
    "\n",
    "prediction = model_best.predict(X_test)\n",
    "probas = model_best.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# расчёт метрик качества\n",
    "metrics = {}\n",
    "\n",
    "_, err1, _, err2 = confusion_matrix(y_test, prediction, normalize='all').ravel()\n",
    "auc = roc_auc_score(y_test, probas)\n",
    "precision = precision_score(y_test, prediction)\n",
    "recall = recall_score(y_test, prediction)\n",
    "f1 = f1_score(y_test, prediction)\n",
    "logloss = log_loss(y_test, prediction)\n",
    "\n",
    "# запишите значения метрик в словарь\n",
    "metrics[\"err1\"] = err1\n",
    "metrics[\"err2\"] = err2\n",
    "metrics[\"auc\"] = auc\n",
    "metrics[\"precision\"] = precision\n",
    "metrics[\"recall\"] = recall\n",
    "metrics[\"f1\"] = f1\n",
    "metrics[\"logloss\"] = logloss\n",
    "\n",
    "\n",
    "# дополнительные метрики из результатов кросс-валидации\n",
    "metrics[\"mean_fit_time\"] = cv_results['mean_fit_time'].mean() # среднее время обучения\n",
    "metrics[\"std_fit_time\"] =  cv_results['std_fit_time'].mean() # стандартное отклонение времени обучения\n",
    "metrics[\"mean_test_score\"] = cv_results['mean_test_score'].mean()  # средний результат на тесте\n",
    "metrics[\"std_test_score\"] = cv_results['std_test_score'].mean()  # стандартное отклонение результата на тесте\n",
    "metrics['best_score'] = clf.best_score_  # лучший результат кросс-валидации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5a7e6332",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mle-user/.venv/lib/python3.10/site-packages/mlflow/models/signature.py:212: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  inputs = _infer_schema(model_input) if model_input is not None else None\n",
      "/home/mle-user/.venv/lib/python3.10/site-packages/_distutils_hack/__init__.py:15: UserWarning: Distutils was imported before Setuptools, but importing Setuptools also replaces the `distutils` module in `sys.modules`. This may lead to undesirable behaviors or errors. To avoid these issues, avoid using distutils directly, ensure that setuptools is installed in the traditional way (e.g. not an editable install), and/or make sure that setuptools is always imported before distutils.\n",
      "  warnings.warn(\n",
      "/home/mle-user/.venv/lib/python3.10/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml\n",
      "  warnings.warn(\n",
      "Registered model 'search_model_sergey_s' already exists. Creating a new version of this model...\n",
      "2025/09/29 15:46:42 INFO mlflow.tracking._model_registry.client: Waiting up to 60 seconds for model version to finish creation. Model name: search_model_sergey_s, version 2\n",
      "Created version '2' of model 'search_model_sergey_s'.\n"
     ]
    }
   ],
   "source": [
    "# настройки для логирования в MLFlow\n",
    "pip_requirements = 'requirements.txt'\n",
    "signature = mlflow.models.infer_signature(X_test, prediction)\n",
    "input_example = X_test[:10]\n",
    "\n",
    "experiment = mlflow.get_experiment_by_name(EXPERIMENT_NAME)\n",
    "if experiment is None:\n",
    "    experiment_id = mlflow.create_experiment(EXPERIMENT_NAME)\n",
    "else:\n",
    "    experiment_id = experiment.experiment_id\n",
    "\n",
    "with mlflow.start_run(run_name=RUN_NAME, experiment_id=experiment_id) as run:\n",
    "    run_id = run.info.run_id # ваш код здесь\n",
    "    \n",
    "    model_info = mlflow.catboost.log_model( \n",
    "\t\t\tcb_model=model_best,\n",
    "            signature=signature,\n",
    "            input_example=input_example,\n",
    "            #code_path=code_paths,\n",
    "            await_registration_for=60,\n",
    "            artifact_path=\"models\",\n",
    "            registered_model_name=REGISTRY_MODEL_NAME,\n",
    "            pip_requirements=pip_requirements)\n",
    "\n",
    "    mlflow.log_metrics(metrics) \n",
    "    mlflow.log_params(best_params)\n",
    "    cv_info = mlflow.sklearn.log_model(cv, artifact_path='cv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
